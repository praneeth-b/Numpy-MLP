{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist():\n",
    "    # The code to download the mnist data original came from\n",
    "    # https://cntk.ai/pythondocs/CNTK_103A_MNIST_DataLoader.html\n",
    "    \n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import struct\n",
    "\n",
    "    try: \n",
    "        from urllib.request import urlretrieve \n",
    "    except ImportError: \n",
    "        from urllib import urlretrieve\n",
    "\n",
    "    def load_data(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x3080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if n != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} entries.\".format(num_samples)\n",
    "                    )\n",
    "                crow = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                ccol = struct.unpack(\">I\", gz.read(4))[0]\n",
    "                if crow != 28 or ccol != 28:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected 28 rows/cols per image.\"\n",
    "                    )\n",
    "                # Read data.\n",
    "                res = np.frombuffer(\n",
    "                    gz.read(num_samples * crow * ccol), dtype=np.uint8\n",
    "                )\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples, crow, ccol)) / 256\n",
    "\n",
    "\n",
    "    def load_labels(src, num_samples):\n",
    "        print(\"Downloading \" + src)\n",
    "        gzfname, h = urlretrieve(src, \"./delete.me\")\n",
    "        print(\"Done.\")\n",
    "        try:\n",
    "            with gzip.open(gzfname) as gz:\n",
    "                n = struct.unpack(\"I\", gz.read(4))\n",
    "                # Read magic number.\n",
    "                if n[0] != 0x1080000:\n",
    "                    raise Exception(\"Invalid file: unexpected magic number.\")\n",
    "                # Read number of entries.\n",
    "                n = struct.unpack(\">I\", gz.read(4))\n",
    "                if n[0] != num_samples:\n",
    "                    raise Exception(\n",
    "                        \"Invalid file: expected {0} rows.\".format(num_samples)\n",
    "                    )\n",
    "                # Read labels.\n",
    "                res = np.frombuffer(gz.read(num_samples), dtype=np.uint8)\n",
    "        finally:\n",
    "            os.remove(gzfname)\n",
    "        return res.reshape((num_samples))\n",
    "\n",
    "\n",
    "    def try_download(data_source, label_source, num_samples):\n",
    "        data = load_data(data_source, num_samples)\n",
    "        labels = load_labels(label_source, num_samples)\n",
    "        return data, labels\n",
    "    \n",
    "    \n",
    "    # Not sure why, but yann lecun's website does no longer support \n",
    "    # simple downloader. (e.g. urlretrieve and wget fail, while curl work)\n",
    "    # Since not everyone has linux, use a mirror from uni server.\n",
    "    #     server = 'http://yann.lecun.com/exdb/mnist'\n",
    "    server = 'https://raw.githubusercontent.com/fgnt/mnist/master'\n",
    "    \n",
    "    # URLs for the train image and label data\n",
    "    url_train_image = f'{server}/train-images-idx3-ubyte.gz'\n",
    "    url_train_labels = f'{server}/train-labels-idx1-ubyte.gz'\n",
    "    num_train_samples = 60000\n",
    "\n",
    "    print(\"Downloading train data\")\n",
    "    train_features, train_labels = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "    # URLs for the test image and label data\n",
    "    url_test_image = f'{server}/t10k-images-idx3-ubyte.gz'\n",
    "    url_test_labels = f'{server}/t10k-labels-idx1-ubyte.gz'\n",
    "    num_test_samples = 10000\n",
    "\n",
    "    print(\"Downloading test data\")\n",
    "    test_features, test_labels = try_download(url_test_image, url_test_labels, num_test_samples)\n",
    "    \n",
    "    return train_features, train_labels, test_features, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/train-images-idx3-ubyte.gz\n",
      "Done.\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/train-labels-idx1-ubyte.gz\n",
      "Done.\n",
      "Downloading test data\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/t10k-images-idx3-ubyte.gz\n",
      "Done.\n",
      "Downloading https://raw.githubusercontent.com/fgnt/mnist/master/t10k-labels-idx1-ubyte.gz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels, test_features, test_labels = get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from tqdm import tqdm \n",
    "\n",
    "class ImgGenerator:\n",
    "    \"\"\"A basic Data augmentation method which generates four additional images per image sample     \n",
    "    by moving the image left,right, up and down by 2 pixels each. \n",
    "    An increase of ~ 0.5% in test accuracy was observed in models trained with augmented data.\n",
    "    \"\"\"\n",
    "    def __init__(self, orig_img, orig_label):\n",
    "        \"\"\" param orig_img : image sample from the original trianing dataset\n",
    "            param orig_label: label of the sample from original training dataset \n",
    "        \"\"\"\n",
    "        self.orig_img = orig_img\n",
    "        self.orig_label = orig_label\n",
    "        self.generated_imgs = []\n",
    "        self.labels = []\n",
    "         \n",
    "    \n",
    "    def shift_vertical(self, arr, num, fill_value=0.0):\n",
    "        \"\"\" shifts the 2d image up/down by n pixels. Positive num implies shift up \n",
    "            and negative num implies shift down\n",
    "        \"\"\"\n",
    "        result = np.empty_like(arr)\n",
    "        if num > 0:\n",
    "            result[:num] = fill_value\n",
    "            result[num:] = arr[:-num]\n",
    "        elif num < 0:\n",
    "            result[num:] = fill_value\n",
    "            result[:num] = arr[-num:]\n",
    "        else:\n",
    "            result[:] = arr\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def shift_horizontal(self, arr, num, fill_value=0.0):\n",
    "        \"\"\" shifts the image left/right by n pixels. Positive num implies shift right \n",
    "            and negative num implies shift left\n",
    "        \"\"\"\n",
    "        result = np.empty_like(arr)\n",
    "        if num > 0 :\n",
    "            result[:,:num] = fill_value\n",
    "            result[:, num:] = arr[:,:-num]\n",
    "        elif num < 0 :\n",
    "            result[:, num:] = fill_value\n",
    "            result[:, :num] = arr[:,-num:]\n",
    "\n",
    "        else :\n",
    "            result[:] = arr\n",
    "\n",
    "        return result\n",
    "  \n",
    "    \n",
    "    def generate_im(self, shift_x, shift_y):  \n",
    "        \"\"\" call this function to generate the pixel shifted images.\n",
    "            param shift_x: num of pixels to shift horizontally\n",
    "            param shift_y: num of pixels to shift verically\n",
    "            return: Augmented training data - \n",
    "                    4 shifted images and 1 original image for each img in the training data\n",
    "        \"\"\"\n",
    "        \n",
    "        for img, label in zip(self.orig_img, self.orig_label):\n",
    "            \n",
    "            right_shift = self.shift_horizontal(img, shift_x)\n",
    "            left_shift  = self.shift_horizontal(img, -shift_x)\n",
    "            up_shift = self.shift_vertical(img, -shift_y)\n",
    "            down_shift = self.shift_vertical(img, shift_y)            \n",
    "\n",
    "            self.generated_imgs.extend([img, right_shift, left_shift, up_shift, down_shift])\n",
    "            self.labels.extend([label]*5)\n",
    "            \n",
    "            \n",
    "        print(\"Shifted Image generation complete\")\n",
    "        return self.generated_imgs, self.labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted Image generation complete\n"
     ]
    }
   ],
   "source": [
    "# #use the generated images to train the ANN\n",
    "\n",
    "gen_img, gen_label = ImgGenerator(train_features, train_labels).generate_im(2,2) # shifting 2 pixels\n",
    "gen_img = np.array(gen_img)\n",
    "gen_label = np.array(gen_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original training data shape was:  (60000, 784) (60000,)\n",
      "the generated shifted image dataset shape is:  (300000, 784) (300000,)\n"
     ]
    }
   ],
   "source": [
    "#Reshape the data\n",
    "gen_img_reshape = gen_img.reshape(-1,28*28)\n",
    "train_features_reshape = train_features.reshape(-1, 28*28)\n",
    "test_features_reshape = test_features.reshape(-1, 28*28)\n",
    "print(\"The original training data shape was: \",train_features_reshape.shape, train_labels.shape)\n",
    "print(\"the generated shifted image dataset shape is: \", gen_img_reshape.shape, gen_label.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_split(x, y, frac):\n",
    "    \"\"\" split the training dataset into training and validation data\n",
    "    \"\"\"\n",
    "    lx = len(x)\n",
    "    p = np.random.permutation(len(x))\n",
    "    \n",
    "    return x[p[:int(lx*frac)]], y[p[:int(lx*frac)]], x[p[int(lx*frac):]], y[p[int(lx*frac):]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\" Base class for variables and parameters\n",
    "    \"\"\"\n",
    "    def __init__(self, value, operation):\n",
    "        self.value = np.array(value)\n",
    "        self.operation = operation\n",
    "        \n",
    "    \n",
    "#     def backprop(self):\n",
    "#         # We define the backpropagation code later.\n",
    "#         return backprop(self)\n",
    "    \n",
    "class Parameter(Variable):\n",
    "    \"\"\"\n",
    "    This class should be used for Variables that are learnable.\n",
    "   \n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        super().__init__(value, operation=None)\n",
    "        self.gradient = np.zeros_like(self.value)\n",
    "        \n",
    "class Input(Variable):\n",
    "    \"\"\"\n",
    "    This class should be used as wrapper for inputs that are not learnable.\n",
    "    \"\"\"\n",
    "    def __init__(self, value):\n",
    "        super().__init__(value, operation=None)\n",
    "        \n",
    "\n",
    "class Layer:\n",
    "    \"\"\" Base layer class.  \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.parameters = []\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\" to be implemented in the subclasses\n",
    "            implement the forward transformation in each layer\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "        \n",
    "    def add_param(self, values):\n",
    "        \"\"\" All trainable parameters of the layer are appended to the 'parameters' attribute\n",
    "        \"\"\"\n",
    "        param = Parameter(values)\n",
    "        self.parameters.append(param)\n",
    "        return param\n",
    "    \n",
    "    def update_parameters(self, optimizer):\n",
    "        \"\"\" called after each backpropogation\n",
    "        param optimizer: here it is the SGD optimizer\n",
    "        \"\"\"\n",
    "        for param in self.parameters:\n",
    "            optimizer.update(param)\n",
    "        \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    \"\"\" Layer class that performs a linear transformation on the data in the MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, in_units, out_units):\n",
    "        \"\"\" Initialize weights and biases here. Dimensions based on in_units and out_units\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        small_value = 0.01\n",
    "        weight_vals = np.random.uniform(\n",
    "                    size=[in_units, out_units],\n",
    "                    low=-small_value,\n",
    "                    high=small_value\n",
    "                    )\n",
    "        self.W = self.add_param(weight_vals)\n",
    "        self.b = self.add_param(np.zeros(shape=out_units))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        def backward(D):\n",
    "            #print(self.__class__.__name__)\n",
    "            \n",
    "            self.W.gradient = self.W.gradient + X.T @ D  \n",
    "                                 \n",
    "            self.b.gradient = self.b.gradient + np.sum(D,axis=0) \n",
    "           \n",
    "            return D @ self.W.value.T\n",
    "       \n",
    "       \n",
    "        return X @ self.W.value + self.b.value, backward\n",
    "    \n",
    "    \n",
    "class Sequential(Layer):\n",
    "    \"\"\" Models the multi layer perceptron. layers can only be cascaded one after the other.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *layers):\n",
    "        \"\"\"  args *layers: pass multiple cascaded layers of the MLP as arguments to this class constructor\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for layer in layers:\n",
    "            self.parameters.extend(layer.parameters) \n",
    "        \n",
    "    def forward(self, X):\n",
    "        backprops = []\n",
    "        op = X\n",
    "        for layer in self.layers:\n",
    "            op, backprop = layer.forward(op)\n",
    "            backprops.append(backprop)\n",
    "\n",
    "        def backward(D):\n",
    "            for backprop in reversed(backprops):\n",
    "                D = backprop(D)\n",
    "            return D\n",
    "        return op , backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    \"\"\"As a non linear activation layer\n",
    "    \"\"\"\n",
    "    def forward(self, X):\n",
    "        mask = X > 0\n",
    "        return X * mask, lambda D: D * mask\n",
    "        \n",
    "    \n",
    "    \n",
    "class Sigmoid(Layer):\n",
    "    \"\"\" As a non linear activation layer\n",
    "    \"\"\"\n",
    "    def forward(self, X):\n",
    "        op = 1/(1+np.exp(-X))\n",
    "        \n",
    "        def backward(D):\n",
    "            \"\"\" The gradient at output is computed with respect to output of the final affine layer\n",
    "            hence the backward just propogates the previous derivative computed for the loss function.\n",
    "            \"\"\"\n",
    "            return D #* op * (1 - op)\n",
    "        \n",
    "        return op, backward\n",
    "    \n",
    "class SGDOptimizer():\n",
    "    def __init__(self, lr=0.1):\n",
    "        self.lr = lr\n",
    "\n",
    "    def update(self, param):\n",
    "        param.value = param.value - self.lr * param.gradient \n",
    "        param.gradient.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(predictions, targets, epsilon=1e-11):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: predictions ndarray\n",
    "           targets  ndarray        \n",
    "    Returns: scalar Cross Entropy loss\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions))/N\n",
    "    return ce , predictions - targets   \n",
    "\n",
    "\n",
    "\n",
    "def mse_loss(Y_, Y):\n",
    "    diff = Y_ - Y.reshape(Y_.shape)\n",
    "    return np.square(diff).mean(), 2 * diff / len(diff)\n",
    "\n",
    "    \n",
    "\n",
    "def one_hot_encoder(x_label):\n",
    "    \"\"\" returns one hot encoded arrays for the input data labels\n",
    "    \"\"\"\n",
    "    rows = x_label.shape[0]\n",
    "    oh_x = np.zeros((rows, 10))\n",
    "    for i in range(rows):\n",
    "        oh_x[i][x_label[i]] = 1\n",
    "    \n",
    "    return oh_x\n",
    "\n",
    "class Softmax(Layer):\n",
    "    def forward(self,X):\n",
    "        exps = np.exp(X - np.max(X))\n",
    "        def backward(D):\n",
    "            return D\n",
    "        return exps / np.sum(exps), backward\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm import tqdm\n",
    "\n",
    "class DigitLearner():\n",
    "    \"\"\" Class to train the MLP. \n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def fit_batch(self,X,Y):\n",
    "        \"\"\" Performs forward and backward operation on one batch of training samples\n",
    "            param X : A batch of training data\n",
    "            param Y : A corresponding batch of training labels\n",
    "        \"\"\"\n",
    "        Y_, backward = self.model.forward(X)\n",
    "        L , D = self.loss(Y_, Y)          \n",
    "                                \n",
    "        backward(D)\n",
    "        self.model.update_parameters(self.optimizer)\n",
    "        return L\n",
    "  \n",
    "    def fit(self, X, Y, epochs, bs):\n",
    "        \"\"\" Fits the entire training data in batches\n",
    "            param X : entire training data\n",
    "            param Y : entire training labels\n",
    "            param bs : batch size for SGD\n",
    "            return : an array of training losses of each epoch \n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        \n",
    "        #pbar = tqdm(total=epochs)\n",
    "        for epoch in range(epochs):\n",
    "            p = np.random.permutation(len(X))\n",
    "            L = 0\n",
    "           \n",
    "            for i in range(0, len(X), bs):\n",
    "                X_batch = X[p[i:i + bs]]\n",
    "                Y_batch = Y[p[i:i + bs]]\n",
    "                L += self.fit_batch(X_batch, Y_batch)\n",
    "                  \n",
    "            losses.append(L)\n",
    "\n",
    "           # pbar.update(1)\n",
    "        print(\"Training complete\")\n",
    "        return losses\n",
    "    \n",
    "    def predict(self, xtest):\n",
    "        \"\"\" predict the output given an input batch of samples\n",
    "        \"\"\"\n",
    "        ypred, _ = self.model.forward(xtest)\n",
    "        return ypred.argmax(axis=-1)\n",
    "    \n",
    "    def accuracy(y_pred, y_test):\n",
    "        return np.sum(y_pred == y_test)/y_pred.shape[0]\n",
    "    \n",
    "    def dump_params(self,filename):\n",
    "        \"\"\" writes the trained weights to a json file\n",
    "        \"\"\"\n",
    "        with open(filename, 'w') as fp:\n",
    "            json.dump([p.value.tolist() for p in self.model.parameters],fp)\n",
    "            print(\"weights written to file\")\n",
    "            \n",
    "    def load_params(self, filename):\n",
    "        \"\"\" loads weights from a json file and initializes the ANN with the loaded weights\n",
    "        \"\"\"\n",
    "        with open(filename) as fp:\n",
    "            loaded_params = json.load(fp)\n",
    "        for p, p_value in zip(self.model.parameters, loaded_params):\n",
    "            p.value = p_value\n",
    "        print(\"Loaded given weights!!\")\n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "totol training time = 1302.6253955364227 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run this block to train the ANN. Training time ~ 20 minutes \n",
    "import time \n",
    "\n",
    "hidden_neurons = 512\n",
    "lrate = 0.008\n",
    "epochs = 35\n",
    "batch = 32\n",
    "X = gen_img_reshape \n",
    "Y = one_hot_encoder(gen_label)  \n",
    "X_test = test_features_reshape\n",
    "Y_test = test_labels\n",
    "\n",
    "# create a ANN with 784 inputs, 1 hidden layer and 10 outputs\n",
    "test = DigitLearner(\n",
    "    Sequential(\n",
    "        AffineLayer(784, hidden_neurons), \n",
    "        ReLU(), \n",
    "        AffineLayer(hidden_neurons, 10),\n",
    "        Sigmoid()        \n",
    "    ), \n",
    "    cross_entropy, \n",
    "    SGDOptimizer(lr=lrate)\n",
    ")\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model to the generated training data\n",
    "losses = test.fit(X, Y, epochs=epochs, bs=batch)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"totol training time =\",end_time-start_time,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights written to file\n"
     ]
    }
   ],
   "source": [
    "# save weights to a json file\n",
    "test.dump_params(\"1lyr_512_0.008_99_17_ep_wt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: 99.17 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(losses, label='training loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "acc = DigitLearner.accuracy(test.predict(X_test), Y_test)\n",
    "\n",
    "print(\"Test accuracy is:\",acc*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
